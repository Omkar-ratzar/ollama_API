# Conversation_context_engine
A stateful LLM backend with Redis-based conversation memory. 
Trying to design it for production ready LLM integrations by handling the context gracefully and optimizing it wherever possible. 
